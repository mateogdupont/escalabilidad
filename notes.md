**Sobre el informe 4+1:**  
- <span style="color:red"> 游댠 major:</span> Un sistema tan complejo como el que desarrollaron ustedes, donde se tienen Chunks, DataFragments, QueryInfo, mensajes con meta informaci칩n para entender la ruta que van a tomar, etc.. merece tener una documentaci칩n a la altura para que cualquier persona lo pueda entender. Esto no lo explican en ning칰n lado, podr칤an haber explicado c칩mo se relacionan estas clases y como funcionan con un diagrama de clase en la vista l칩gica, o con una descripci칩n textual.
- <span style="color:yellow"> 仇뎘inor:</span> Ser칤a bueno sumar sobre las flechas del DAG, los campos/atributos que se env칤an en cada mensaje, para entender qu칠 cosas se filtran (por ejemplo).
- <span style="color:yellow"> 仇뎘inor:</span> En la entrega no se especific칩 en ning칰n lado las instrucciones para ejecutar el sistema.

**Sobre el c칩digo / soluci칩n:**
- <span style="color:red"> 游댠 major:</span> La ejecuci칩n de la demo grabada demor칩 m치s de 1 hora. Esto es un tiempo bastante grande y habla de optimizaciones que no se hicieron pero que pudieron haberse hecho. 
- <span style="color:red"> 游댠 major:</span> ~~La funci칩n update_data_fragment_step de query_updater se invoca m칰ltiples veces entre los distintos tipos de nodo, para cada fragmento (cada review o libro, osea al menos 3 millones de veces), por ejemplo en los filtros tienen:~~

```py
    def filter_data_chunk(self,chunk: DataChunk):
        for fragment in chunk.get_fragments():
            if self.exit:
                return
            if self.filter_data_fragment(fragment):
                # -> c칩digo actualizado <-
```

~~La llamada a update_data_fragment_step parece inofensiva, pero se hace casi 2 veces por cada data fragment (2 * 3M), solamente en los filtros, y esa funci칩n por dentro tiene m칰ltiples loops con evaluaciones del estilo _update_first_query() a las cuales se le pasa como par치metro data_fragment.clone()~~

~~쮼s necesario clonar la informaci칩n? 쮼s necesario calcular varias veces en el mismo filtro, nodo, etc los "next steps"? Esto que parece inofensivo, es copiar memoria una y otra vez, millones de veces, y me parece que se puede evitar pasando una referencia al objeto en lugar de una copia, y en el filtro/nodo calculando una s칩la vez los "next steps" para el fragmento. Vi uso de clone() en varios lugares, el uso de esto debe estar bien justificado, ya que implica copiar memoria y con los vol칰menes de informaci칩n que manejamos parece ser una mala idea. Este punto est치 relacionado con el primero, ya que les pega en la performance y puede contribuir a que el sistema les tarde tanto en ejecutar.~~

- <span style="color:red"> 游댠 major:</span> Otro punto relacionado al descarte temprano de datos para mejorar la eficiencia. La Query 3 pide "T칤tulos y autores de libros publicados en los 90' con al menos 500 rese침as.". Sin embargo, en todo los steps intermedios que tiene la Query 3, nunca descartan el atributo "review/text" (el que tiene varios bytes de texto libre), si descartaran esa informaci칩n innecesaria lo antes posible, tendr치n menos cantidad de datos viajando por la red y replicados en memoria, por lo tanto mejor rendimiento. El campo "review/text" se necesita 칰nicamente para el c치lculo del sentimient, cosa que podr칤an hacer en una etapa temprana sin pasar por varios steps (y sin hacer varios .clones() innecesarios como les marqu칠 en el punto anterior).

- <span style="color:red"> 游댠 major:</span> Fragmento de c칩digo del Joiner

```py
    def save_book_in_table(self,book: Book, query_id: str):
        if query_id not in self.books_side_tables.keys():
            self.books_side_tables[query_id] = {}
        self.books_side_tables[query_id][book.get_title()] = book
```

쮺omo funciona esta side table? Por que es necesaria una array de arrays en lugar de un mapa title -> book ? Ac치 pueden tener informaci칩n redundante, otro punto que puede pegar en la performance. Adem치s, vi que devuelven NACK en el joiner si falta info en la side table. Esto lo pueden evitar haciendo lo que les coment칠 en alg칰n meet: primero ingestan libros, luego env칤an EOF, y ahi sus nodos saben que pueden empezar a leer reviews.

- <span style="color:red"> 游댠 major:</span> En el m칠todo read_chunk_with_columns de client.py se pueden perder mensajes si el archivo no tiene una cantidad de registros exactamente igual a un m칰ltiplo de CHUNK_SIZE.

- <span style="color:red"> 游댠 major:</span> Uso de sleeps() en varios puntos del c칩digo, en forma injustificada. 쮸 que se deben estos sleeps? Pueden evidenciar malas pr치cticas de sincronizaci칩n.

- <span style="color:red"> 游댠 major:</span> Filtran datos en client-side. En la funci칩n "parse_data" de client.py se toman algunos atributos de data pero otros se setean en NoNe. Esto es un filtrado que se hace del lado del cliente. Esto deber칤a hacerse del lado del servidor. Adem치s, veo que no filtran todos los datos innecesarios, y esto les puede estar afectando a los tiempos de ejecuci칩n (ejemplo: id de review, helpfulness, summary, son datos que no se necesitan para nada). Los datos deben filtrarse del lado del servidor, el nodo data_cleaner es un buen candidato. Aqu칤 mismo tienen que eliminar esas columnas que no se necesitan para que no les meta datos innecesarios en todas las etapas posteriores.

- <span style="color:yellow"> 仇뎘inor:</span> Confuso algoritmo de formaci칩n de chunks y de conformaci칩n de data_fragments. En parse_data de client.py, desambiguan si el dato es un libro o una review por la cantidad de columnas del registro, si casualmente tuvieran la misma cantidad de "columnas" relevantes este algoritmo no servir칤a. Se confunde sem치nticamente los chunks que leen del disco, con los chunks de informaci칩n que contienen data fragments. Toda esta sobre-comlpejidad se podr칤a haber documentado en un diagrama de clases aprovechando la vista l칩gica.

- <span style="color:orange"> 丘멆잺 medium: </span>  El TP exige que siempre se contesten las 5 queries, esto es algo que pueden asumir y que va a ser siempre cierto. Hay 3 millones de reviews, entonces al menos van a tener 1 mill칩n de data fragments, todos ellos con el valor de queries en "1,2,3,4,5"... Ese string tiene 9 bytes, multipliquen por 3 millones y eso son datos innecesarios que tienen en memoria, viajando por red, etc...


**<span style="color:#7DDA58"> Arreglos: </span>**
- Se eliminaron las llamadas repetidas a `update_data_fragment_step`. Ahora se hace una 칰nica vez por fragmento en cada nodo (y si es necesario, sino no).
- Se redujeorn la cantidad de clones a la m칤nima necesaria en `update_data_fragment_step`. Como esa funci칩n demultiplexa es imposible evitar los clones, pero se redujeron al m칤nimo.
- Respecto a los clones que se hacen en el nodo `counter`, fueron todos reemplazados por hacer el data fragment desde cero, ya que s칩lo contiene las queries que le corresponden.